---
title: "Untitled"
author: "Rachel Sinondang"
date: "2/26/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Business case:  
- mengembangkan suatu bisnis/ perusahaan menggunakan sentiment analysis. Caranya adalah dengna menggunakan sentiment analysis, kita dibantu untuk melihat dan mengerti apa yang customer harapkan/cari dari product kita. Selain itu juga untuk melihat aspek apa yang perlu ditingkatkan (dengan melihat sentiment negative), dan aspek apa yang perlu dipertahankan (dengan melihat sentiment positive) dari product kita.

User:  
- bagian product analyst pada suatu perusahaan

Business process:  
- melihat apakah produk/features yang baru diluncurkan mendapatkan lebih banyak sentiment positif/negative/neutral  
- Mencari kata terbanyak dari masing-masing sentiment  
- Membuat model machine learning  
- Dari data test dilihat kembali kata-kata yang paling banyak muncul pada masing-masing sentiment. 
- Dari sentiment negative pada data test diharapkan dapat melihat aspek apa yang dirasa kurang dan perlu pengembangan  
- Dari sentiment positive pada data test diharapkan dapat melihat aspek apa yang sudah cukup sehingga baik untuk dipertahankan

Aplikasi project lainnya:  
- Social media monitoring. Hal ini penting karena memperlihatkan bahwa company selalu mendengerkan. Selain itu keep an eye on customer opinion.  
- Competitor Analysis. Melalui sentimen analysis kita dapat melihat di aspek apakah competitor kita meraih kesuksesan serta, bagaimana taktik competitor dan apa hal yang kurang dari competitor yang dapat kita kembangkan pada produk kita.  
- Market research. Dari hasil review/survey, dapat dilihat secara demografi mana yang memberi sentiment positif -> inilah yang akan menjadi target
- Customer Analysis (melihat target audience). 


# Memanggil library

```{r message=FALSE, warning=FALSE}
 # Data Wrangling
library(tidyverse) 

# Text analysis
library(textclean)
library(tidytext)
library(tm)
```

# Read data
```{r}
apple <- read.csv("apple-twitter-sentiment-texts.csv")
```

Keterangan:  
- ï..text : kolom review mengenai product apple  
- sentiment : sentiment dari review yang bersangkutan (-1 = negatif, 0 = neutral, 1 = positive)  

# Data Cleansing

```{r}
# mengecek apakah terdapat data NA atau tidak 
colSums(is.na(apple))
```


```{r}
apple_clean <- apple %>%
  mutate(ï..text = ï..text %>%
      str_to_lower() %>% # transform menjadi huruf kecil
      replace_url()  %>% 
      replace_html() %>% 
      str_remove_all("@([0-9a-zA-Z_]+)") %>% # remove username
      str_remove_all("#([0-9a-zA-Z_]+)") %>% # remove hashtag
      replace_contraction() %>%
      replace_word_elongation() %>% 
      replace_internet_slang() %>% 
      replace_emoji(.) %>% 
      replace_emoticon(.) %>% 
      str_remove_all(pattern = "[[:digit:]]") %>% # remove number
      str_remove_all(pattern = "[[:punct:]]") %>% 
      str_remove_all(pattern = "%") %>% 
      str_remove_all(pattern = "\\$") %>% # remove dollar sign
      str_remove_all(pattern = "\\|") %>%
      str_remove_all(pattern = "\\=") %>%
      str_remove_all('[\\&]+') %>% 
      str_remove_all('[\\"]+') %>% 
      str_remove_all("<([0-9a-zA-Z_]+)>") %>%
      str_squish(),  # remove extra whitespace
      sentiment = base::factor(sentiment, levels = c("-1", "0", "1"),labels = c("0","1","2"))
  ) %>%
  na.omit() %>% # membuang baris bernilai NA
  as.data.frame() %>% 
  distinct() %>% # hanya keep data yang unik
  mutate(sentiment = as.factor(sentiment))

```

Keterangan: level sentiment diubah sebab nanti pada split data untuk pembuatan model LSTM classes dimulai dari 0 (pernah dicoba dimulai dari 1 dan error)

```{r}
# slang_word <- lexicon::hash_internet_slang
add_slang_word <- data.frame(x = c("yall", "needa", "gotta", "ain't", "dammit", "rt", "ima"), y = c("you all", "need", "must", "are not", "damn it", "", "i must admit"))

apple_clean$ï..text <- replace_internet_slang(x = apple_clean$ï..text, slang = add_slang_word$x, replacement = add_slang_word$y)

head(apple_clean)
```

# Wordcloud

### Pre-processing

```{r}
jumlah <- apple_clean %>%
  group_by(sentiment) %>%
  summarise(total = n())

library(plotly)
plot_sentiment <- ggplot(data = jumlah ,mapping = aes(x = sentiment, y = total, text = glue(
                         "jumlah: {total}"))) +
  geom_col(aes(fill = sentiment))

ggplotly(plot_sentiment, tooltip = "text")
```

Dari plot di atas terlihat bahwa terdapat ketidakseimbangan pada data sentiment (yang merupakan target kita) di mana yang paling tinggi adalah sentimen neutral dan paling rendah adalah sentiment positif. Selain itu, perbedaan jumlah sentiment negative dan sentiment positive juga cukup besar yaitu sebanyak 539 buah yang mengartikan bahwa secara garis besar konsumen kurang puas terhadap produk apple ini. Untuk mengetahui lebih lanjut mengenai aspek apa yang dirasa kurang dari produk ataupun aspek apa yang sudah baik dari produk, maka kita perlu membuat wordcloud. wordcloud akan memberi tau kita kata apa yang paling banyak muncul pada masing-masing sentiment. 

### Membuat Wordcloud

```{r message =FALSE, warning=FALSE}
apple_aa <- apple_clean %>% 
  unnest_tokens(word, ï..text)%>%
  mutate(word = textstem::lemmatize_words(word)) %>%
  anti_join(stop_words) %>% 
  count(word, sentiment, sort = T) %>% 
  group_by(sentiment) %>% 
  top_n(25)

library(ggthemes)

ggplot(apple_aa %>% filter(sentiment == "0"), aes(label = word)) +
  ggwordcloud::geom_text_wordcloud(aes(size=n), color = "#FF3333") +
  facet_wrap(~sentiment, scales = "free_y") +
  scale_size_area(max_size = 12) +
  labs(title = "Negative Sentiment's Wordcloud") +
  theme_minimal()
```

```{r}
ggplot(apple_aa %>% filter(sentiment == "1"), aes(label = word)) +
  ggwordcloud::geom_text_wordcloud(aes(size=n), color = "#0000FF") +
  facet_wrap(~sentiment, scales = "free_y") +
  scale_size_area(max_size = 12) +
  labs(title = "Neutral Sentiment's Wordcloud") +
  theme_minimal()
```

```{r}
ggplot(apple_aa %>% filter(sentiment == "2"), aes(label = word)) +
  ggwordcloud::geom_text_wordcloud(aes(size=n), color = "#00FF00") +
  facet_wrap(~sentiment, scales = "free_y") +
  scale_size_area(max_size = 12) +
  labs(title = "Positif Sentiment's Wordcloud") +
  theme_minimal()
```

Insight dari wordcloud:  
- beberapa kata terbanyak pada sentiment negative : battery, charger, update, music. Dari insight ini dapat dikatakan bahwa perlu adanya perbaikan/peningkatan pada aspek battery,charger, update, music.  
- pada sentiment neutral : watch, tv, blog. Melalui insight ini dapat dikatakan bahwa konsumen sudah cukup puas mengenai ketiga aspek ini namun baik juga apabila dapat ditingkatkan lagi sehingga mendapat sentimen positif.  
- pada sentiment positive : computer, team, photo, service, sale, market. Dari insight ini dapat dikatakan bahwa konsumen puas dengan aspek computer, team, photo, service, sale dan market apple. Aspek-aspek ini perlu untuk tetap dipertahankan.  

### Memanggil library keras  

Model akan dibuat menggunakan keras oleh sebab itu kita perlu memanggil library keras.  
```{r}
reticulate::use_python("C:/Users/ASUS/anaconda3/envs/r-tensorflow",required = T)
library(keras)
use_condaenv("r-tensorflow")
```

### Remove stopwords dan lemmatize: 
```{r}

rm.stopwords <- VCorpus(VectorSource(apple_clean$ï..text)) %>% # ubah kolom menjadi corpus karena fungsi-fungsi tm bisa diterapkan hanya pada tipe corpus
  tm_map(removeWords,stopwords("en")) %>% # untuk membuang kata-kata, pada kasus ini berdasarkan kamus stopwords 
  tm_map(content_transformer(textstem::lemmatize_words)) %>%
  tm_map(stripWhitespace) %>% # menghapus spasi yang double
  sapply(as.character) %>%
  as.data.frame(stringsAsFactors = FALSE)

apple.clean <- bind_cols(rm.stopwords, apple_clean[,2]) %>%
  `colnames<-`(c("text","label"))
# data[,2] karena label ada di kolom kedua

head(apple.clean)
```

### Tokenizer  

Tahap ini untuk memisahkan tiap kata di seluruh dokumen menjadi bentuk token. Parameter `num_words` untuk mengatur jumlah maksimum kata yang akan digunakan, di sort berdasarkan urutan frekuensi yang terbesar. 'num_words' yang saya pilih adalah sebanyak 1024 (tidak baku)  
```{r}
num_words <- 1024 # jumlah vocabulary yang akan dipakai

# prepare tokenizers
tokenizer <- text_tokenizer(num_words = num_words, lower = TRUE) %>% 
  fit_text_tokenizer(apple.clean$text)

paste(
  "Total Unique Words:", length(tokenizer$word_counts),"|", #cek unik words
  "Total Features:", num_words # cek feature kita berapa
)
```
### Splitting Data

Splitting data dilakukan untuk memisahkan antara data untuk dilatih (train), data validasi dan data untuk test (dalam kasus real, ini adalah unseen data)  
```{r}
library(rsample)
set.seed(100)

# split into train - test
split <- initial_split(apple.clean, prop =  0.6, strata = "label")
apple_train <- training(split)
apple_test <- testing(split)

# split data test to test - validation
split_val <- initial_split(apple_test, prop = 0.5, strata = "label")
apple_val <- training(split_val)
apple_test <- training(split_val)
```

Dikarenakan banyaknya data pada masing-masing kelas sentimen terbilang imbalance, perlu dilakukan upsample.  
```{r}
library(caret)

apple_up_train <- upSample(x = apple_train %>% select(-label), # data prediktor
                         y = as.factor(apple_train$label), # data label
                         yname = "label") # nama kolom label

table(apple_up_train$label)
```

### Split x & y

```{r}
maxlen_1 <- max(str_count(apple.clean$text, "\\w+")) + 1 # Text cutoff
  
# prepare x
app_train_x <- texts_to_sequences(tokenizer, apple_up_train$text) %>%
  pad_sequences(maxlen = maxlen_1)

app_val_x <- texts_to_sequences(tokenizer, apple_val$text) %>%
  pad_sequences(maxlen = maxlen_1)

app_test_x <- texts_to_sequences(tokenizer, apple_test$text) %>%
  pad_sequences(maxlen = maxlen_1)

# prepare y
app_train_y <- to_categorical(apple_up_train$label, num_classes = 3)
app_val_y <- to_categorical(apple_val$label, num_classes = 3)
app_test_y <- to_categorical(apple_test$label, num_classes = 3)
```

# Membuat model Deep Learning

## Membangun Arsitektur

Karena kita akan mengklasifikasi review menjadi tiga kelas sentiment, maka kita set output sebanyak 3 serta activation adalah softmax. Untuk jumlah hidden layer dan nodes pada hidden layar, jumlahnya bebas. Pada model ini saya menggunakan sebuah hidden layer dengan masing-masing nodes sebanyak 8. Terlalu banyak nodes maupun hidden layer dapat menyebabkan kondisi overfitting di mana model baik dalam prediksi data train namun tidak baik dalam prediksi data test.  
```{r message=FALSE, warning=FALSE}
# initiate keras model sequence
model_apple <- keras_model_sequential()

# model
model_apple %>%
  # layer input
  layer_embedding(
    name = "input",
    input_dim = num_words, # jumlah feature : ukuran dari vocabulary
    input_length = maxlen_1, # banyak max dari sequence (sesuai dengan nilai pad_sequence)
    output_dim = 4
  ) %>%
  # layer dropout
  layer_dropout(
    name = "embedding_dropout",
    rate = 0.5
  ) %>%
  # layer lstm 1
  layer_lstm(
    name = "lstm1",
    units = 8,
    dropout = 0.5,
    recurrent_dropout = 0.5, 
    return_sequences = FALSE, 
  ) %>%
  # layer output
  layer_dense(
    name = "output",
    units = 3,
    activation = "softmax"
  )
```

```{r}
# compile the model
model_apple %>% compile(
  optimizer = optimizer_adam(lr=0.005),
  metrics = "accuracy",
  loss = "categorical_crossentropy"
)

# model summary
summary(model_apple)
```

### Model Fitting  

Setelah arsitektur model dibangun, kini saatnya fitting data train dan data validasi pada arsitektur model kita.  
```{r}
# model fit settings
set.seed(100)
epochs <- 25
batch_size <- 17

# fit the model
history <- model_apple %>% fit(
  app_train_x, app_train_y,
  batch_size = batch_size, 
  epochs = epochs,
  verbose = 1,
  validation_data = list(
    app_val_x, app_val_y
  )
)

```

Dari hasil fitting, didapatkan akurasi sekitar 0.7 dan tidak terjadi overfitting.  

```{r message=FALSE, warning=FALSE}
# predict on test
app_test_pred <- model_apple %>%
  predict_classes(app_test_x) %>%
  as.vector()

library(yardstick)
# performance on "unseen data"
accuracy_vec(
 truth = factor(apple_test$label,labels = c("negative", "neutral", "positive")),
 estimate = factor(app_test_pred, labels = c("negative", "neutral", "positive"))
)
```
Dari hasil evaluasi model, kita mendapatkan akurasi sekitar 0.7. Namun untuk lebih memastikan, dilakukan confusionMatrix untuk melihat akurasi dari masing-masing kelas.  
```{r}
library(caret)
confusionMatrix(data = as.factor(app_test_pred), # hasil prediksi
                reference = apple_test$label)
```
Dari hasil confusionMatrix didapatkan bahwa akurasi masing-masing kelas sekitar 0.6 hingga 0.8 atau dapat dikatakan tidak terdapat kejomplangan akurasi 
